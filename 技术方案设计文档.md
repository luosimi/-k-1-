# 相似图片检索工具 - 详细技术实施规范 (Developer Guide)

## 1. 项目愿景与目标

构建一个高性能的本地相似图片检索工具。
**核心价值**: 让用户能通过一张图片，快速在本地海量图库中找到相似素材。
**关键指标**:

* **精度**: 使用 `ViT-H-14` (1024维) 模型，确保检索结果在视觉语义上高度相关。
* **速度**: 毫秒级检索响应 (Top-K)。
* **易用性**: 自动化索引管理，用户无感知增量更新。

---

## 2. 系统架构与技术选型

### 2.1 技术栈清单

| 组件                   | 选型            | 版本要求 (建议) | 备注                     |
| :--------------------- | :-------------- | :-------------- | :----------------------- |
| **语言**         | Python          | 3.9+            | 确保类型提示支持         |
| **深度学习框架** | PyTorch         | 2.0+            | 需支持 CUDA (NVIDIA GPU) |
| **模型库**       | open_clip_torch | 2.20+           | 加载 ViT-H-14            |
| **Web 框架**     | Flask           | 2.3+            | 轻量级 HTTP 服务         |
| **图像处理**     | Pillow (PIL)    | 10.0+           | 图片加载与预处理         |
| **数值计算**     | NumPy           | 1.24+           | 矩阵运算                 |
| **数据处理**     | Pandas          | 2.0+            | CSV 读写优化             |

### 2.2 目录结构规范

```text
ImageSearchTool/
├── app.py                  # [Entry] Flask 主程序，负责路由分发
├── config.py               # [Config] 配置加载与常量定义
├── core/
│   ├── __init__.py
│   ├── model_loader.py     # [Singleton] 模型加载单例，负责显存管理
│   ├── feature_extractor.py# [Service] 图像 -> 1024维向量
│   ├── indexer.py          # [Service] 文件扫描、增量更新、CSV读写
│   └── search_engine.py    # [Service] 内存向量检索、Top-K计算
├── utils/
│   ├── file_utils.py       # 文件哈希、mtime获取、图片合法性检查
│   └── math_utils.py       # Base64与Numpy互转
├── data/
│   └── index.csv           # (Auto) 图片特征索引库
├── static/                 # 前端静态资源
├── templates/              # 前端 HTML 模板
└── requirements.txt        # 依赖列表
```

---

## 3. 核心模块详细设计 (Implementation Details)

### 3.1 数据存储规范 (Schema Design)

**文件**: `data/index.csv`
**编码**: UTF-8
**分隔符**: `,` (Comma)

| 字段名        | 类型   | 说明                                         |
| :------------ | :----- | :------------------------------------------- |
| `filename`  | string | 图片相对路径 (相对于用户设置的根目录)        |
| `mtime`     | float  | 文件最后修改时间戳 (用于增量检测)            |
| `embedding` | string | **Base64 编码** 的 1024维 float32 向量 |

> **开发者注意**:
> 不要直接存储 1024 列 float。
>
> * **序列化**: `base64.b64encode(numpy_array.astype(np.float32).tobytes()).decode('utf-8')`
> * **反序列化**: `np.frombuffer(base64.b64decode(b64_str), dtype=np.float32)`

### 3.2 模块接口定义 (API Specification)

#### A. `core.model_loader.ModelWrapper`

负责管理显存中唯一的模型实例。

```python
class ModelWrapper:
    def __init__(self, model_name='ViT-H-14', pretrained='laion2b_s32b_b79k'):
        # 1. 自动检测 device (cuda/cpu)
        # 2. 加载 model, preprocess
        # 3. 开启 eval() 模式
        pass

    def encode(self, image_tensor) -> np.ndarray:
        # 执行推理，返回归一化的 numpy 向量
        pass
```

#### B. `core.indexer.Indexer`

负责维护 CSV 索引。

```python
class Indexer:
    def __init__(self, root_dir: str, csv_path: str):
        self.root_dir = root_dir
        self.csv_path = csv_path

    def sync(self, model_wrapper, progress_callback=None):
        """
        全量同步逻辑:
        1. 扫描 self.root_dir 获取 {path: mtime} 字典 (current_files)
        2. 读取 self.csv_path 获取 {path: mtime} 字典 (indexed_files)
        3. 计算 diff:
           - to_add: in current but not in indexed
           - to_update: in both but mtime changed
           - to_remove: in indexed but not in current
        4. 执行 to_remove: 从内存 DataFrame 中删除
        5. 执行 to_add/to_update:
           - 批处理 (Batch Size = 32)
           - 读图 -> model_wrapper.encode -> base64 -> 写入 DataFrame
           - 每 N 批次 save_csv 一次 (Checkpoint)
        """
        pass
```

#### C. `core.search_engine.SearchEngine`

负责内存中的快速检索。

```python
class SearchEngine:
    def load_index(self, csv_path: str):
        # 1. Pandas 读取 CSV
        # 2. 解析 base64 列为大矩阵 (N, 1024)
        # 3. 矩阵归一化 (虽然模型输出已归一化，建议再次检查)
        self.features = ... # np.array
        self.paths = ...    # list

    def search(self, query_vec: np.ndarray, top_k=50) -> List[Dict]:
        # 1. 计算 scores = self.features @ query_vec.T
        # 2. indices = np.argsort(-scores)[:top_k]
        # 3. 组装结果: [{'path': p, 'score': s}, ...]
        pass
```

---

## 4. 开发流程指南 (Step-by-Step)

### 阶段一：核心算法验证 (Prototype)

1. 编写脚本 `poc.py`。
2. 实现 `ViT-H-14` 加载和单张图片推理。
3. 验证 `Base64` 序列化/反序列化逻辑，确保精度无损失。
4. **产出**: 可运行的向量提取函数。

### 阶段二：索引器实现 (Indexer)

1. 实现文件扫描器，支持递归遍历文件夹，过滤非图片文件 (.jpg, .png, .webp)。
2. 实现增量更新逻辑 (Diff 算法)。
3. **关键点**: 处理坏图（`try-except` 包裹 `Image.open`），打印日志但不中断。
4. **产出**: 能将文件夹转换为 `index.csv` 的脚本。

### 阶段三：Web 服务与检索 (Service)

1. 搭建 Flask 骨架。
2. 实现 `/api/config` 接口：设置图库路径。
3. 实现 `/api/sync` 接口：触发索引更新（建议使用 `threading` 异步执行，返回 task_id）。
4. 实现 `/api/search` 接口：接收 `multipart/form-data` 图片，返回 JSON 结果。
5. **产出**: 后端 API 完备。

### 阶段四：前端 UI 集成

1. **设置页**: 路径输入框 + "开始同步"按钮 + 进度条 (轮询 `/api/status`)。
2. **搜索页**: 拖拽上传区域 + 瀑布流/网格展示结果。
3. **图片服务**: Flask 需要实现一个路由 `send_from_directory` 来让前端能访问本地图片。

---

## 5. 异常处理与健壮性 (Robustness)

1. **显存溢出 (OOM)**:
   * 在 `Indexer` 中严格控制 `Batch Size`。
   * 如果使用 GPU，在推理前后手动调用 `torch.cuda.empty_cache()`。
2. **并发冲突**:
   * **互斥锁**: 索引正在更新时，搜索请求应被阻塞或返回特定状态；或者使用读写锁（搜索读内存旧数据，索引写新数据）。
3. **路径编码**:
   * 处理中文文件名、空格、特殊符号。在 CSV 中存储相对路径，前端展示时 URL Encode。

## 6. 性能优化建议

1. **启动速度**:
   * `ViT` 模型加载较慢。建议 Web 服务启动时**懒加载**模型，或者在启动日志中明确提示“正在加载模型...”。
2. **搜索速度**:
   * 如果图片数量 < 10万，`NumPy` 暴力计算完全足够。
   * 如果 > 10万，考虑引入 `Faiss` 库构建 `IVF` 索引。
3. **UI 体验**:
   * 搜索结果图片应使用**懒加载 (Lazy Load)**。
   * 后端可增加 `/api/thumbnail` 接口，实时生成缩略图，减少前端加载大图的带宽压力。

## 7. 配置文件示例 (config.json)

```json
{
  "gallery_path": "E:\\MyPhotos",
  "model_name": "ViT-H-14",
  "device": "cuda", 
  "index_path": "./data/index.csv"
}
```
